{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openfe import transform, tree_to_formula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from autogluon.core.metrics import make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "import os\n",
    "import zipfile\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv(filename=\"feature_engineering.env\", usecwd=True, raise_error_if_not_found=True))\n",
    "os.environ[\"KAGGLE_USERNAME\"] = os.getenv(\"KAGGLE_USERNAME\")\n",
    "os.environ[\"KAGGLE_KEY\"] = os.getenv(\"KAGGLE_KEY\")\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from kaggle.api_client import ApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "COMPETITION_NAME = \"playground-series-s3e11\"\n",
    "TARGET = 'cost'\n",
    "DATA_PATH = f\"data/{COMPETITION_NAME}/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from Kaggle\n",
    "api = KaggleApi(ApiClient())\n",
    "api.authenticate()\n",
    "api.competition_download_files(COMPETITION_NAME, path=DATA_PATH)\n",
    "zip_file = os.path.join(DATA_PATH, f\"{COMPETITION_NAME}.zip\")\n",
    "with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(DATA_PATH)\n",
    "os.remove(zip_file)\n",
    "os.remove(f\"{DATA_PATH}/test.csv\")\n",
    "os.remove(f\"{DATA_PATH}/sample_submission.csv\")\n",
    "print(f\"Data downloaded to {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the plot directory exists\n",
    "plot_directory = \"plots\"\n",
    "if not os.path.exists(plot_directory):\n",
    "    os.makedirs(plot_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the dataset\n",
    "df = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "df.columns = df.columns.str.replace(r\"[.\\(\\) ]\", \"_\", regex=True)\n",
    "print(f\"Data shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=1)\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Validation shape: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares = [0.05, 0.1, 0.2, 0.3, 0.4] # Sample shares to calculate the bins for\n",
    "sample_bins_size = calculate_sample_bins(shares, train_df) # Calculate the sample bins\n",
    "print(sample_bins_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the time and features for different sample shares, also record OpenFE for the biggest sample\n",
    "time_simulation, top_features, ofe = estimate_time_and_features(sample_bins_size, train_df, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the time for OpenFE based on the size of the stratified sample\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(time_simulation.keys()), list(time_simulation.values()), marker='o')\n",
    "plt.xlabel(\"Share of the stratified sample\")\n",
    "plt.ylabel(\"Time for OpenFE (min)\")\n",
    "plt.title(\"Time for OpenFE based on the size of the stratified sample\")\n",
    "plt.grid()\n",
    "# save the plot to the plots directory\n",
    "plt.savefig(f\"{plot_directory}/time_simulation.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visualization showing relationship between sample size and hit rate\n",
    "hit_rate = calculate_hit_rate(top_features, baseline=0.4)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(hit_rate.keys()), list(hit_rate.values()), marker='o')\n",
    "# add values to the plot above of the markers\n",
    "for sample_share, rate in hit_rate.items():\n",
    "    plt.text(sample_share, rate, f\"{rate:.2f}\", ha='right')\n",
    "plt.xlabel(\"Share of the stratified sample\")\n",
    "plt.ylabel(\"Hit rate\")\n",
    "plt.title(\"Hit rate based on the size of the stratified sample\")\n",
    "plt.grid()\n",
    "plt.savefig(f\"{plot_directory}/hit_rate.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))  # Create a 2x2 grid of subplots\n",
    "axs = axs.flatten()  # Flatten the 2x2 grid to easily iterate over it\n",
    "\n",
    "# Assuming sample_bins_zie is defined and stratified_sample function is available\n",
    "for i, (sample_share, bin_size) in enumerate(sample_bins_size.items()):\n",
    "    if i >= 4:\n",
    "        break  # We only have space for 4 subplots in the 2x2 grid\n",
    "\n",
    "    X_train_fe, y_train_fe = stratified_sample(train_df, target=TARGET, size_per_bin=bin_size, bins=20)\n",
    "\n",
    "    # Plot original data distribution in the current subplot\n",
    "    axs[i].hist(train_df[TARGET], bins=50, color='blue', alpha=0.5, label='Original data', density=True)\n",
    "    axs[i].hist(y_train_fe, bins=50, color='red', alpha=0.5, label='Sample data', density=True)\n",
    "    axs[i].set_title(f\"Target distribution for sample share: {sample_share}\")\n",
    "    axs[i].set_xlabel(TARGET)\n",
    "    axs[i].set_ylabel(\"Frequency\")\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to not overlap subplots\n",
    "plt.savefig(f\"{plot_directory}/target_distribution.png\")\n",
    "\n",
    "plt.show()  # Display the figure with the 2x2 grid of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_size = sample_bins_size[0.4]\n",
    "X_train_fe, y_train_fe = stratified_sample(train_df, target=TARGET, size_per_bin=bin_size, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the feature names\n",
    "names = {}\n",
    "for i in range(20):\n",
    "    feature_name = tree_to_formula(ofe.new_features_list[i])\n",
    "    adj_feature_name = re.sub(r\"[.() ,+\\-*/]\", replace_match, feature_name)\n",
    "    names[f\"autoFE_f_{i}\"] = 'A_' + adj_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 5 names\n",
    "for key, value in list(names.items())[:5]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RMSLE metric for AutoGluon\n",
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle = make_scorer('rmsle', root_mean_squared_log_error, greater_is_better=False, needs_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for topk in [0,5,10,15,20]:\n",
    "    X_train_ofe, X_val_ofe = transform(train_df, val_df, ofe.new_features_list[:topk], n_jobs=4)\n",
    "    scores[topk], feature_importance = get_AutoGluon_score(X_train_ofe, X_val_ofe, TARGET, metric=rmsle, preset='best_quality', time_min=5)\n",
    "    print(f'Top {topk} features score: {scores[topk]}')\n",
    "    \n",
    "# rename columns for feature importance\n",
    "feature_importance = feature_importance.rename(index=names)\n",
    "feature_importance[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot improvements in score based on additional features with labels \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(scores.keys()), list(scores.values()), marker='o')\n",
    "plt.text(0, list(scores.values())[0], f'{list(scores.values())[0]:.4f}', ha='right')\n",
    "# add values to the plot above of the markers\n",
    "for topk, score in scores.items():\n",
    "    plt.text(topk, score, f\"{score:.4f}\", ha='right')\n",
    "plt.xlabel('Top k features')\n",
    "plt.ylabel('RMSLE')\n",
    "plt.title('RMSLE vs Top k features')\n",
    "\n",
    "# Save plot to file\n",
    "plt.savefig('plots/rmsle_vs_top_k_features.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
